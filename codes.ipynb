{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruijing-xiong/Spoon-Knife/blob/main/codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZrPe84TdyJR"
      },
      "source": [
        "#loading necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAh03RM1d2ca"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn import preprocessing\n",
        "import math\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, RationalQuadratic as RQ, WhiteKernel, ExpSineSquared as Exp, DotProduct as Lin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsQU5AeIfMoR"
      },
      "source": [
        "#Step1: Get inputs from google sheets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPhbEw6yfLri"
      },
      "outputs": [],
      "source": [
        "#function to get user input values\n",
        "def get_inputs(worksheet):\n",
        "  \n",
        "  #select the second column\n",
        "  inputs = worksheet.col_values(2)\n",
        "\n",
        "  #first row is empty\n",
        "\n",
        "  ##Get crop type and model number from google sheets\n",
        "  crop_type = inputs[1]\n",
        "  model_num = inputs[2]\n",
        "  print(f\"crop type: {crop_type}, model num: {model_num}\")\n",
        "\n",
        "  ##Get location from google sheets\n",
        "  country= inputs[3]\n",
        "\n",
        "  try:\n",
        "      city = inputs[4]\n",
        "  except IndexError as error:\n",
        "      city =''\n",
        "\n",
        "  try:\n",
        "      zipcode = inputs[5]\n",
        "  except IndexError as error:\n",
        "      zipcode =''\n",
        "      \n",
        "  print(f\"city: {city},zipcode: {zipcode}, country: {country}\")\n",
        "\n",
        "  return (city,zipcode, country, crop_type,model_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG5ef9xRkxl3"
      },
      "source": [
        "#Step 2: Location indicators\n",
        "\n",
        "Converting location to longtitude and latitude   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y0f9v9G_Vom"
      },
      "outputs": [],
      "source": [
        "from geopy.exc import GeocoderTimedOut\n",
        "from geopy.geocoders import Nominatim\n",
        "   \n",
        "# function to find the coordinate of a given city \n",
        "def findGeocode(city,zipcode,country):\n",
        "\n",
        "  #specify state to avoid the same city name in different states\n",
        "  if country == 'United States' :\n",
        "    location = zipcode+ ' '+country\n",
        "\n",
        "  else: \n",
        "    location = city+' '+country\n",
        "\n",
        "    # try and catch is used to overcome\n",
        "    # the exception thrown by geolocator\n",
        "    # using geocodertimedout  \n",
        "  try:\n",
        "      geolocator = Nominatim(user_agent=\"your_app_name\")\n",
        "      loc = geolocator.geocode(location)\n",
        "\n",
        "      print(\"address:\", loc, \"\\nlatitude:\",loc.latitude, \"\\nlongitude:\",loc.longitude)\n",
        "      return (loc.latitude,loc.longitude)\n",
        "      \n",
        "\n",
        "  except GeocoderTimedOut:\n",
        "      return findGeocode(city,zipcode,country)    \n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGmRt-ccSgOJ"
      },
      "source": [
        "## Weather parameters by using API from open-meteo.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmUl5l4lkw3l"
      },
      "outputs": [],
      "source": [
        "\n",
        "#function to find weather based on the coordinate of a given city by using API\n",
        "def weather_parameter(df, longitude,latitude):\n",
        "\n",
        "  import requests\n",
        "  import json\n",
        "  \n",
        "  ###Use this one units are SI: pressure in hPa, prcp is in mm, wspd in km/hr and temp in C\n",
        "  response=requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true&hourly=surface_pressure,precipitation&forecast_days=1\") # data from METEO\n",
        "\n",
        "  weather=json.loads(response.text)\n",
        "  \n",
        "  #get current weather\n",
        "  specific_datetime = weather['current_weather']['time']  \n",
        "  index = weather['hourly']['time'].index(specific_datetime)\n",
        "\n",
        "  #store 4 weather parameters\n",
        "  curr_pres = weather['hourly']['surface_pressure'][index]\n",
        "  curr_prcp = weather['hourly']['precipitation'][index]\n",
        "  curr_temp = weather['current_weather']['temperature']\n",
        "  curr_wspd = weather['current_weather']['windspeed']\n",
        "  \n",
        "  current_weather  = [curr_prcp,curr_wspd,curr_pres,curr_temp]\n",
        "  print(f\"original value: curr_prcp': {curr_prcp}, curr_temp:{curr_temp},\\\n",
        "  curr_wspd:{curr_wspd}, curr_pres:{curr_pres}\")\n",
        "  \n",
        "  #weather range\n",
        "  f = df['curr_prcp']\n",
        "  g = df['curr_wspd']\n",
        "  h = df['curr_pres']\n",
        "  i = df['curr_temp']\n",
        "\n",
        "#make sure weather data is within the range of the existing dataset\n",
        "\n",
        "  min_range = {'curr_prcp':np.min(f),'curr_wspd':np.min(g),'curr_pres':np.min(h),'curr_temp':np.min(i)}\n",
        "  max_range = {'curr_prcp':np.max(f),'curr_wspd':np.max(g),'curr_pres':np.max(h),'curr_temp':np.max(i)}\n",
        "\n",
        "#curr_prcp:\n",
        "#  message = ''\n",
        "  if curr_prcp < min_range.get('curr_prcp'):\n",
        "#    message = 'current prcp'+curr_prcp+' is out of range，min value '+ min_range.get('curr_prcp') +' is applied'\n",
        "    curr_prcp = round(min_range.get('curr_prcp'))\n",
        "  if curr_prcp > max_range.get('curr_prcp'):\n",
        "#    message = 'current prcp'+curr_prcp+' is out of range，max value '+ max_range.get('curr_prcp') +' is applied'\n",
        "    curr_prcp = round(max_range.get('curr_prcp'))\n",
        "  else: \n",
        "    curr_prcp\n",
        "#    message\n",
        "\n",
        "#curr_wspd:\n",
        "  if curr_wspd < min_range.get('curr_wspd'):\n",
        "#    message = 'current prcp'+curr_prcp+' is out of range，min value '+ min_range.get('curr_prcp') +' is applied'\n",
        "    curr_wspd = round(min_range.get('curr_wspd'))\n",
        "  if curr_wspd > max_range.get('curr_wspd'):\n",
        "#    message = 'current prcp'+curr_prcp+' is out of range，max value '+ max_range.get('curr_prcp') +' is applied'\n",
        "    curr_wspd = round(max_range.get('curr_wspd'))\n",
        "  else: \n",
        "    curr_wspd\n",
        "\n",
        "#curr_pres:\n",
        "  if curr_pres < min_range.get('curr_pres'):\n",
        "#    message = 'current prcp'+curr_prcp+' is out of range，min value '+ min_range.get('curr_prcp') +' is applied'\n",
        "    curr_pres = round(min_range.get('curr_pres'))\n",
        "  if curr_pres > max_range.get('curr_pres'):\n",
        "#    message = 'current prcp'+curr_prcp+' is out of range，max value '+ max_range.get('curr_prcp') +' is applied'\n",
        "    curr_pres = round(max_range.get('curr_pres'))\n",
        "  else: \n",
        "    curr_pres\n",
        "\n",
        "#curr_temp:\n",
        "  if curr_temp < min_range.get('curr_temp'):\n",
        "#    message = 'current prcp'+curr_prcp+' is out of range，min value '+ min_range.get('curr_prcp') +' is applied'\n",
        "    curr_temp = round(min_range.get('curr_temp'))\n",
        "  if curr_temp > max_range.get('curr_temp'):\n",
        "#    message = 'current prcp'+curr_prcp+' is out of range，max value '+ max_range.get('curr_prcp') +' is applied'\n",
        "    curr_temp = round(max_range.get('curr_temp'))\n",
        "  else: \n",
        "    curr_temp\n",
        "\n",
        "  print(f\"curr_prcp': {curr_prcp}, curr_temp:{curr_temp},\\\n",
        "  curr_wspd:{curr_wspd}, curr_pres:{curr_pres}\")\n",
        "  \n",
        "  return curr_prcp,curr_wspd,curr_pres,curr_temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sTIMEIF64Pr"
      },
      "source": [
        "#Step 3: clean and slicing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY2XQmdO64Pr"
      },
      "outputs": [],
      "source": [
        "def clean(df,crop_type,model_num):\n",
        "  \n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "  #get target variables\n",
        "  df['delta'] = (df['broken_grain_actual']+df['mog_actual']-df['yield'])\n",
        "\n",
        "  # Creating an instance of the sklearn.preprocessing.MinMaxScaler()\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  #scale the data\n",
        "  df[[\"ScaledBG\", \"ScaledMOG\", \"ScaledYield\"]] = scaler.fit_transform(df[[\"broken_grain_actual\",\"mog_actual\", \"yield\"]])\n",
        "  \n",
        "  #create scalled target variables\n",
        "  df[\"ScaledDelta\"] = df[\"ScaledBG\"] + df[\"ScaledMOG\"] - df[\"ScaledYield\"]\n",
        "  df[\"ScaledDelta\"]  \n",
        "\n",
        "  #drop unneccessary columns\n",
        "  df1 = df.drop(['hist_pres', 'hist_wspd', 'hist_prcp', 'hist_temp', 'timestamp',\\\n",
        "                 'telemetry_date', 'latitude', 'longitude'], axis=1)\n",
        "  df2 = df1.drop(['broken_grain_goal', 'mog_goal', 'yield', 'delta', 'broken_grain_actual', 'mog_actual', 'ScaledBG', 'ScaledMOG', 'ScaledYield', 'grain_loss_rotor', 'grain_loss_shoe', 'serial_num'], axis=1)\n",
        "  \n",
        "  # replacing WET CORN and DRY CORN to CORN\n",
        "  df2['crop_type'].mask(df2['crop_type'] == 'DRY CORN', 'CORN', inplace=True)\n",
        "  df2['crop_type'].mask(df2['crop_type'] == 'WET CORN', 'CORN', inplace=True)\n",
        "\n",
        "  # Merge combine 7 and 8\n",
        "  df2['model_num'] = df2['model_num'].replace(7, 8)\n",
        "  df2['model_num'] = df2['model_num'].replace(7, 8)\n",
        "  df2['model_num'] = df2['model_num'].replace(7, 8)\n",
        "\n",
        "  # Merge combine 9 and 10\n",
        "  df2['model_num'] = df2['model_num'].replace(9, 10)\n",
        "  df2['model_num'] = df2['model_num'].replace(9, 10)\n",
        "  df2['model_num'] = df2['model_num'].replace(9, 10)\n",
        "\n",
        "  # slicing data frame based on 3 crop types 'WHEAT', 'CORN', 'SOYBEAN'.\n",
        "  # variable to hold input data frame\n",
        "  in_df = df2\n",
        "\n",
        "  #identify crop df\n",
        "  #if matches with the input values\n",
        "  crop_df = in_df.loc[(in_df['crop_type'] == crop_type)]\n",
        "\n",
        "  # identify model_num df \n",
        "  if '8' in model_num:\n",
        "    new_df = crop_df.loc[(crop_df['model_num'] == 8)]\n",
        "\n",
        "  if '10' in model_num:\n",
        "    new_df = crop_df.loc[(crop_df['model_num'] == 10)]\n",
        "\n",
        "  # drop columns\n",
        "  new_df = new_df.drop(['crop_type', 'model_num'], axis=1)\n",
        "  new_df = new_df.dropna()\n",
        "\n",
        "  #default settings\n",
        "  default_corn={'cleaning_fan_speed':950,'chaffer_position':20, 'sieve_position':16,'rotor_speed':400, 'concave_position':22}\n",
        "  default_soybeans={'cleaning_fan_speed':950,'chaffer_position':18, 'sieve_position':14,'rotor_speed':650, 'concave_position':14}\n",
        "  default_wheat={'cleaning_fan_speed':850,'chaffer_position':16, 'sieve_position':12,'rotor_speed':850, 'concave_position':12}\n",
        "\n",
        "  setting = {'CORN':default_corn,'SOYBEANS':default_soybeans, 'WHEAT':default_wheat}\n",
        "\n",
        "  default_setting = setting.get(crop_type)\n",
        "\n",
        "\n",
        "  return new_df, default_setting\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cIPigTel0mk"
      },
      "source": [
        "#Step 4: Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAXlRH9akXmM"
      },
      "source": [
        "**Set up weather parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8znrzt-NvgVd"
      },
      "outputs": [],
      "source": [
        "def GaussianProcessRegressor(df,curr_prcp,curr_temp,curr_wspd,curr_pres,default_setting):\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "  from mpl_toolkits.mplot3d import Axes3D\n",
        "  from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "  from sklearn.gaussian_process.kernels import RBF\n",
        "  import scipy.optimize as opt\n",
        "  from scipy.optimize import LbfgsInvHessProduct\n",
        "  import numpy as np\n",
        "  from scipy.optimize import minimize\n",
        "\n",
        "  # Create scatter plot\n",
        "  a = df['cleaning_fan_speed']\n",
        "  b = df['chaffer_position']\n",
        "  c = df['sieve_position']\n",
        "  d = df['rotor_speed']\n",
        "  e = df['concave_position']\n",
        "  f = df['curr_prcp']\n",
        "  g = df['curr_wspd']\n",
        "  h = df['curr_pres']\n",
        "  i = df['curr_temp']\n",
        "  z = df['ScaledDelta']\n",
        "\n",
        "  # Define kernel for Gaussian Process Regressor\n",
        "  kernel = RBF()\n",
        "\n",
        "  # Create Gaussian Process Regressor object\n",
        "  gpr = GaussianProcessRegressor(kernel=RBF())\n",
        "\n",
        "  # Fit the Gaussian Process Regressor to the scatter plot data\n",
        "  X = np.vstack((a, b, c, d, e, f, g, h, i)).T\n",
        "  gpr.fit(X, z)\n",
        "\n",
        "  # Interpolate new x and y values using the Gaussian Process Regressor\n",
        "  new_fan = np.arange(default_setting.get('cleaning_fan_speed')-150,151+default_setting.get('cleaning_fan_speed'),50)\n",
        "  new_chaffer = np.arange(default_setting.get('chaffer_position')-8,9+default_setting.get('chaffer_position'))\n",
        "  new_sieve = np.arange(default_setting.get('sieve_position')-6,7+default_setting.get('sieve_position'))\n",
        "  new_rotor = np.arange(default_setting.get('rotor_speed')-150,151+default_setting.get('rotor_speed'),50)\n",
        "  new_concave = np.arange(default_setting.get('concave_position')-10,11+default_setting.get('concave_position'))\n",
        "  new_f = round(curr_prcp)\n",
        "  new_g = round(curr_wspd)\n",
        "  new_h = round(curr_pres)\n",
        "  new_i = round(curr_temp)\n",
        "  X_new = np.meshgrid(new_fan, new_chaffer, new_sieve, new_rotor, new_concave, new_f, new_g, new_h, new_i)\n",
        "  X_new_2d = np.array((X_new[0].flatten(), X_new[1].flatten(), X_new[2].flatten(),X_new[3].flatten(),X_new[4].flatten(),X_new[5].flatten(), X_new[6].flatten(), X_new[7].flatten(), X_new[8].flatten())).T\n",
        "\n",
        "  z_pred1, sigma = gpr.predict(X_new_2d, return_std=True)\n",
        "\n",
        "  # find coords of min in z_pred\n",
        "  min_idx = np.argmin(z_pred1)\n",
        "  print(f'min delta: {z_pred1[min_idx]}')\n",
        "\n",
        "  results =[str(round(X_new_2d[min_idx,0])),str(round(X_new_2d[min_idx,1])),\\\n",
        "            str(round(X_new_2d[min_idx,2])),str(round(X_new_2d[min_idx,3])), \\\n",
        "            str(round(X_new_2d[min_idx,4]))]\n",
        "  print(f'ideal values: \\ncleaning_fan_speed: {round(X_new_2d[min_idx,0])},\\\n",
        "          \\nchaffer_position: {round(X_new_2d[min_idx,1])},\\\n",
        "          \\nsieve_position: {round(X_new_2d[min_idx,2])},\\\n",
        "          \\nrotor_speed: {round(X_new_2d[min_idx,3])},\\\n",
        "          \\nconcave_position: {round(X_new_2d[min_idx,4])},\\\n",
        "          \\ncurr_prcp: {round(X_new_2d[min_idx,5])},\\\n",
        "          \\ncurr_wspd: {round(X_new_2d[min_idx,6])},\\\n",
        "          \\ncurr_pres: {round(X_new_2d[min_idx,7])},\\\n",
        "          \\ncurr_temp: {round(X_new_2d[min_idx,8])}')\n",
        "  return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHBzOTlpoiNY"
      },
      "source": [
        "#Step 5: Update Google sheets and display recommended settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deaCyLW6opq1"
      },
      "outputs": [],
      "source": [
        "\n",
        "##function to update google sheets with recommended settings\n",
        "def update(worksheet,results):\n",
        "  #update google sheet\n",
        "  cell_list = worksheet.range('E2:E6')\n",
        "  #warning_list = worksheet.range('E7:E10')\n",
        "  #gives us a tuple of an index and value\n",
        "  for i, val in enumerate(results):  \n",
        "  #use the index on cell_list and the val from cell_values\n",
        "      cell_list[i].value = val    \n",
        "\n",
        "  worksheet.update_cells(cell_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lxLe9JAfky2"
      },
      "source": [
        "#Main Command"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk9rvF39xzww"
      },
      "source": [
        "##connect with database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USmyEccvd5fo",
        "outputId": "876e75e3-db55-4c8b-8647-d180fd258c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljIkmyucd6EC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('combines_data.csv')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RD2hEePPJvM"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enZazn7PpCWI"
      },
      "source": [
        "**open and read values on google sheets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BndyRoUEPSYe"
      },
      "outputs": [],
      "source": [
        "from google.auth import default\n",
        "import gspread\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "worksheet = gc.open('combine_settings_inputs').sheet1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkWK-NekxtN3"
      },
      "source": [
        "##running models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T52BBV1ImgwD"
      },
      "source": [
        "**reading inputs from google sheets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb3IfyHYfzjl",
        "outputId": "55388c57-e8af-445c-ab05-f9d4c1c418df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crop type: CORN, model num: 7-8\n",
            "city: ,zipcode: 61701, country: United States\n"
          ]
        }
      ],
      "source": [
        "city,zipcode,country,crop_type,model_num = get_inputs(worksheet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thDa-gY7AEwX"
      },
      "source": [
        "**converting address to latitude and longtitude**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqrSINbCAoup",
        "outputId": "d260a804-56c4-44d1-93e0-541cb55327eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "address: Bloomington, McLean County, Illinois, 61701, United States \n",
            "latitude: 40.47972329777424 \n",
            "longitude: -88.98931991081082\n"
          ]
        }
      ],
      "source": [
        "latitude, longitude= findGeocode(city,zipcode,country)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c58JS5pVmjvG"
      },
      "source": [
        "**getting weather parameters from website**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaoCT00vicvT",
        "outputId": "692481e0-d05f-48a0-b0bf-3eb922baaedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original value: curr_prcp': 0.0, curr_temp:13.2,  curr_wspd:8.0, curr_pres:984.2\n",
            "curr_prcp': 0.0, curr_temp:13.2,  curr_wspd:8.0, curr_pres:1005\n"
          ]
        }
      ],
      "source": [
        "curr_prcp,curr_temp,curr_wspd,curr_pres = weather_parameter(df, longitude,latitude)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOuyqBMSmsEK"
      },
      "source": [
        "**clean data and make it ready to run models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNZT_Nd9mHKb"
      },
      "outputs": [],
      "source": [
        "processed_data,default_setting = clean(df,crop_type,model_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6AmO991nc6J"
      },
      "source": [
        "**getting outputs from Gussian Process Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0TWoZNEnkcd"
      },
      "outputs": [],
      "source": [
        "#RBF\n",
        "output = GaussianProcessRegressor(processed_data,curr_prcp,curr_temp,curr_wspd,curr_pres,default_setting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5_PU9OGpfK_"
      },
      "source": [
        "**updating google sheet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKQ8qFXXo0rT"
      },
      "outputs": [],
      "source": [
        "update(worksheet,output)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TZrPe84TdyJR",
        "JsQU5AeIfMoR",
        "_sTIMEIF64Pr",
        "8cIPigTel0mk",
        "jB7ztqrkuJIF",
        "IIkQweipuDEe",
        "_khpyyunnTpp"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}